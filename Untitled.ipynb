{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61a009b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-75120f853abd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import pywt\n",
    "import os\n",
    "import math\n",
    "from imutils import face_utils\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "jaffe_dir_path = R\"/jaffedbase/jaffe/\"\n",
    "landmarks_predictor_model = R\"/shape_predictor_68_face_landmarks.dat\"\n",
    "# 7 expressions: [neutral, happy, angry, disgust, fear, sad, surprise]\n",
    "expres_code = ['NE','HA','AN','DI','FE','SA','SU']\n",
    "expressions = [ 0,   1,   2,   3,   4,   5,   6]\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(landmarks_predictor_model)\n",
    "\n",
    "\n",
    "def read_data(dir_path):\n",
    "    img_names = []\n",
    "    img_data_list = []\n",
    "    labels = []\n",
    "    img_list = os.listdir(dir_path)\n",
    "    for img in img_list:\n",
    "        input_img = cv2.imread(dir_path + img, cv2.IMREAD_GRAYSCALE)\n",
    "        img_data_list.append(input_img)\n",
    "        label = img[3:5]  # each name of image have 2 char for label from index 3-5\n",
    "        labels.append(expres_code.index(label))\n",
    "        img_names.append(img)\n",
    "    img_data = np.array(img_data_list)\n",
    "\n",
    "    print(img_data.shape)\n",
    "    return img_data, labels, img_names\n",
    "\n",
    "\n",
    "def rotateImage(image, angle):\n",
    "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    return result\n",
    "\n",
    "\n",
    "def angle_line_x_axis(point1, point2):\n",
    "    angle_r = math.atan2(point1[1] - point2[1], point1[0] - point2[0]);\n",
    "    angle_degree = angle_r * 180 / math.pi;\n",
    "    return angle_degree\n",
    "\n",
    "\n",
    "def detect_eyes(gray):\n",
    "    rects = detector(gray, 1)\n",
    "    # loop over the face detections\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the landmark (x, y)-coordinates to a NumPy array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "        pts_right = shape[36: 42]  # right eye landmarks\n",
    "        pts_left = shape[42: 48]  # left eye landmarks\n",
    "\n",
    "        hull_right = cv2.convexHull(pts_right)\n",
    "        M_right = cv2.moments(hull_right)\n",
    "        # calculate x,y coordinate of center\n",
    "        cX_right = int(M_right[\"m10\"] / M_right[\"m00\"])\n",
    "        cY_right = int(M_right[\"m01\"] / M_right[\"m00\"])\n",
    "        right_eye_center = (cX_right, cY_right)\n",
    "\n",
    "        hull_left = cv2.convexHull(pts_left)\n",
    "        M_left = cv2.moments(hull_left)\n",
    "        # calculate x,y coordinate of center\n",
    "        cX_left = int(M_left[\"m10\"] / M_left[\"m00\"])\n",
    "        cY_left = int(M_left[\"m01\"] / M_left[\"m00\"])\n",
    "        left_eye_center = (cX_left, cY_left)\n",
    "\n",
    "    return left_eye_center, right_eye_center\n",
    "\n",
    "\n",
    "def preprocessing(input_images):\n",
    "    normalized_faces = []\n",
    "    for gray in input_images:\n",
    "        left_eye, rigth_eye = detect_eyes(gray)\n",
    "\n",
    "        angle = angle_line_x_axis(left_eye, rigth_eye)\n",
    "        rotated_img = rotateImage(gray, angle)\n",
    "\n",
    "        # line length\n",
    "        D = cv2.norm(np.array(left_eye) - np.array(rigth_eye))\n",
    "\n",
    "        # center of the line\n",
    "        D_point = [(left_eye[0] + rigth_eye[0]) / 2, (left_eye[1] + rigth_eye[1]) / 2]\n",
    "\n",
    "        # Face ROI\n",
    "        x_point = int(D_point[0] - (0.9 * D))\n",
    "        y_point = int(D_point[1] - (0.6 * D))\n",
    "        width_point = int(1.8 * D)\n",
    "        height_point = int(2.2 * D)\n",
    "        r = [x_point, y_point, width_point, height_point]\n",
    "        face_roi = rotated_img[int(r[1]):int(r[1] + r[3]), int(r[0]):int(r[0] + r[2])]\n",
    "\n",
    "        # resize to (96, 128)\n",
    "        face_roi = cv2.resize(face_roi, (96, 128))\n",
    "\n",
    "        # Equalize Hist\n",
    "        face_roi = cv2.equalizeHist(face_roi)\n",
    "        normalized_faces.append(face_roi)\n",
    "    return normalized_faces\n",
    "\n",
    "\n",
    "def apply_wavelet_transform(images):\n",
    "    normalized_faces = []\n",
    "    for img in images:\n",
    "        coeffs2 = pywt.dwt2(img, 'bior1.3')\n",
    "        LL, (LH, HL, HH) = coeffs2\n",
    "        normalized_faces.append(LL)\n",
    "    return normalized_faces\n",
    "\n",
    "\n",
    "def from_2d_to_1d(images):\n",
    "    normalized_faces = []\n",
    "    for img in images:\n",
    "        tmp = img.reshape(-1)\n",
    "        normalized_faces.append(tmp)\n",
    "    faces_1d = np.array(normalized_faces)\n",
    "    return faces_1d\n",
    "\n",
    "X, Y, img_names = read_data(jaffe_dir_path)\n",
    "cropped_X = preprocessing(X)\n",
    "\n",
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(16, 150))\n",
    "columns = 6\n",
    "rows = int(len(cropped_X)/columns)\n",
    "for i in range(1, columns*rows):\n",
    "    img = cropped_X[i]\n",
    "    ax = fig.add_subplot(rows, columns, i)\n",
    "    type_name = img_names[i][:-5]\n",
    "    ax.set_xlabel(type_name)\n",
    "    plt.imshow(img, cmap = 'gray')\n",
    "plt.show()\n",
    "\n",
    "LL_images = apply_wavelet_transform(cropped_X)\n",
    "X_new = from_2d_to_1d(LL_images)\n",
    "print(X_new.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_new)\n",
    "scaled_data = scaler.transform(X_new)\n",
    "\n",
    "pca = PCA(n_components=35, whiten=False)\n",
    "pca.fit(scaled_data)\n",
    "\n",
    "X_tr, X_ts, y_tr, y_ts = train_test_split(scaled_data, Y, test_size=0.20, random_state=4)\n",
    "X_tr_pca = pca.transform(X_tr)\n",
    "\n",
    "# get best parameters for svm by GridSearch\n",
    "param_grid = { \"C\" : [0.1, 1, 10] , \"gamma\" : [1, 0.1, 0.01]}\n",
    "gs = GridSearchCV(estimator=SVC(kernel='linear'), param_grid=param_grid, scoring='accuracy', refit=True, verbose=2)\n",
    "gs = gs.fit(X_tr_pca, y_tr)\n",
    "\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "\n",
    "bp = gs.best_params_\n",
    "model = SVC(C=bp['C'], kernel='linear', gamma=bp['gamma'])\n",
    "model.fit(X_tr_pca, y_tr)\n",
    "\n",
    "X_ts_pca = pca.transform(X_ts)\n",
    "mean_accuracy = model.score(X_ts_pca, y_ts)\n",
    "predictions = model.predict(X_ts_pca)\n",
    "\n",
    "print(mean_accuracy)\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_ts,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_ts,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c9d6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
